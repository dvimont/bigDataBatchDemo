#!/bin/bash
STORAGE_LEVEL=$1 # MEMDISK or DISK
EXECUTOR_MEM=$2  # 1g, 2g, 4g, etc. -- note that r4.2xlarge machines have 60GB ram
SPARK_MASTER=$3 # note that port is usually 7077
HDFS_MASTER=$4
YEAR=$5  # can also be entered as YEAR/MONTH if only single month to be processed for testing

echo "Removing existing HDFS pageview mapreduce output"
hadoop fs -rm -r /test/pageviews.*

echo "STARTING PageViews Spark processing: " `date -u --rfc-822`

echo "Running SparkDriver job: "  `date -u --rfc-822`
# NOTE: this is customized from an example execution in Learning Spark book
$SPARK_HOME/bin/spark-submit \
  --master $SPARK_MASTER \
  --executor-memory $EXECUTOR_MEM \
  --class org.commonvox.bigdatademos.SparkDriver \
  ./target/bigdatademo01-1.0-SNAPSHOT.jar \
  $HDFS_MASTER $STORAGE_LEVEL \
  /pageviews.hourly/$YEAR \
  pageviews.daily pageviews.weekly pageviews.monthly pageviews.yearly \
    > ./logs/spark_output.log  2>&1

 # args after .jar above == hdfs-url, storage-level, input HDFS file/directory,
 #                            & output daily, weekly, monthly, yearly HDFS files

echo "COMPLETED PageViews Spark processing: " `date -u --rfc-822`
