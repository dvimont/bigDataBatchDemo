#!/bin/bash

PROCESSING_LIMIT=2

echo "Removing existing HDFS test output"
hadoop fs -rm -r /test/

echo "Recreating test directory and subdirectories"
hadoop fs -mkdir /test /test/raw_files

echo "STARTING download from Wikimedia and load into HDFS" `date -u --rfc-822`

rm -r ./raw_files
mkdir ./raw_files
rm ./logs/download.log
rm ./logs/hdfs_move.log

for i in {5..9}
do
   echo "Processing 2015 month $i"
   mvn exec:java -Dexec.mainClass="org.commonvox.bigdatademos.WikimediaFileDownloader" -Dexec.args="https://dumps.wikimedia.org/other/pageviews/2015/2015-0$i/ $PROCESSING_LIMIT" >> ./logs/download.log
   hadoop fs -moveFromLocal ./raw_files/*.* /test/raw_files >> ./logs/hdfs_move.log
done
for i in {10..12}
do
   echo "Processing 2015 month $i"
   mvn exec:java -Dexec.mainClass="org.commonvox.bigdatademos.WikimediaFileDownloader" -Dexec.args="https://dumps.wikimedia.org/other/pageviews/2015/2015-$i/ $PROCESSING_LIMIT" >> ./logs/download.log
   hadoop fs -moveFromLocal ./raw_files/*.* /test/raw_files >> ./logs/hdfs_move.log
done

echo "COMPLETED download processing: " `date -u --rfc-822`
cd ..
