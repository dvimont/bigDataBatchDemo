#!/bin/bash

echo "Removing existing HDFS test output"
hadoop fs -rm -r /test/

echo "Recreating test directory and subdirectories"
hadoop fs -mkdir /test

echo "STARTING download from Wikimedia and load inth HDFS" `date -u --rfc-822`
# java -cp target/bigdatademo01-1.0-SNAPSHOT.jar org.commonvox.bigdatademos.WikimediaFileDownloader sample > loaderLog.txt 2>&1

# mvn exec:java -Dexec.mainClass="org.commonvox.bigdatademos.WikimediaFileDownloader" -Dexec.args="sample" > ./logs/download.log
# following classpath missing hadoop, easier to let Maven exec take care of things -- java -classpath bigdatademo01-1.0-SNAPSHOT.jar org.commonvox.bigdatademos.WikimediaFileDownloader sample >> ./logs/downloadWikimediaFiles.log 2>&1

rm -r ./raw_files
mkdir raw_files
rm ./logs/download.log
rm ./logs/hdfs_move.log

for i in {1..9}
do
   echo "Processing 2015 month $i"
   mvn exec:java -Dexec.mainClass="org.commonvox.bigdatademos.WikimediaFileDownloader" -Dexec.args="https://dumps.wikimedia.org/other/pageviews/2015/2015-0$i 3" >> ./logs/download.log
   hadoop fs -moveFromLocal ./raw_files/ /test >> ./logs/hdfs_move.log
done

echo "COMPLETED download processing: " `date -u --rfc-822`
cd ..
