#!/bin/bash

YEAR=$1
START_MONTH=$2
END_MONTH=$3
INPUT_DIR=/nodelete
HOURLY_DIR=$INPUT_DIR/pageviews.hourly
YEAR_DIR=$HOURLY_DIR/$YEAR
rm ./logs/distcp$YEAR*.log

echo "Creating directory and subdirectories"
hadoop fs -mkdir $INPUT_DIR $HOURLY_DIR $YEAR_DIR
# NOTE that distcp process below will automatically create monthly subdirectories

echo "STARTING download from S3 and load into HDFS for $YEAR, months $START_MONTH thru $END_MONTH" `date -u --rfc-822`

rm ./logs/hdfs_move.log

for (( m=$START_MONTH; m<=$END_MONTH; m++ ))
do
  FORMATTED_MONTH=$(printf "%02d" $m)
  echo "Deleting previously-existing HDFS file/directory in $YEARDIR/$FORMATTED_MONTH"
  hadoop fs -rm -r $YEAR_DIR/$FORMATTED_MONTH
  echo "Submitting distcp job for $YEAR-$FORMATTED_MONTH" `date -u --rfc-822`
  # NOTE that distcp creates new month directory automatically!
  hadoop distcp s3a://wmf-insight-datalake/pageviews/$YEAR/$FORMATTED_MONTH $YEAR_DIR > ./logs/distcp$YEAR$FORMATTED_MONTH.log 2>&1
done

echo "COMPLETED download from S3 and load into HDFS for $YEAR, months $START_MONTH thru $END_MONTH" `date -u --rfc-822`

